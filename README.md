# üåø Tesis Plagas con Im√°genes HD: Detecci√≥n en Cultivos de Papa

Este proyecto implementa y compara **tres escenarios** de clasificaci√≥n para la detecci√≥n de plagas/enfermedades en cultivos de papa a partir de im√°genes de alta resoluci√≥n (HD). El objetivo principal es evaluar c√≥mo diferentes funciones de p√©rdida y arquitecturas manejan el alto desbalance de clases del dataset.

## üìÇ Estructura del Proyecto

El c√≥digo est√° organizado por el tipo de clasificador (CNN o RF) y la funci√≥n de p√©rdida utilizada.

| Carpeta | Contenido | Descripci√≥n |
| :--- | :--- | :--- |
| `data/` | `Plaga/`, `Sana/` | Directorio principal de los datos de entrenamiento y validaci√≥n. **Debe contener las im√°genes.** |
| `data/Plaga` | Im√°genes HD | Muestras de plantaciones de papas con plagas/enfermedades. |
| `data/Sana` | Im√°genes HD | Muestras de plantaciones de papas sanas. |
| `src/` | | C√≥digo fuente principal. |
| `src/cnn/binary_crossentropy/` | | Modelo **Deep Learning (MobileNetV2)** con p√©rdida est√°ndar. |
| `src/cnn/focal_loss/` | | Modelo **Deep Learning (MobileNetV2)** con p√©rdida **Focal Loss** (para desbalance). |
| `src/rf/` | | Modelo **Machine Learning Cl√°sico (Random Forest)** usando CNN para extracci√≥n de *features*. |
| `prueba/` | Im√°genes nuevas | Im√°genes de prueba para los scripts de inferencia (`inference.py`). |
| `requirements.txt`| Dependencias | Lista de librer√≠as necesarias. |

---

## ‚öôÔ∏è Configuraci√≥n y Requisitos

### 1. Crear y Activar el Entorno Virtual

Es fundamental usar un entorno virtual (`venv`) para evitar conflictos de librer√≠as. Ejecuta estos comandos en la carpeta ra√≠z del proyecto.

```bash
# Crear el entorno virtual
python -m venv venv

# Activar en Windows
.\venv\Scripts\activate

# Activar en Linux/macOS
source venv/bin/activate
```

### 2. Instalar Dependencias

Aseg√∫rate de tener un archivo `requirements.txt` que liste todas las librer√≠as necesarias (TensorFlow, scikit-learn, etc.).

```bash
pip install -r requirements.txt
```

## üöÄ Gu√≠a de Ejecuci√≥n Paso a Paso
### I. Escenario: Deep Learning con Binary Cross-Entropy (L√≠nea Base)

Este modelo establece la referencia utilizando la funci√≥n de p√©rdida est√°ndar.

#### 1. Entrenamiento (`train.py`)

El script entrena el modelo CNN y guarda el mejor peso monitoreando el Recall o la Loss de validaci√≥n (dependiendo de la configuraci√≥n del callback).

```bash
python src/cnn/binary_crossentropy/train.py ./data
```

#### 2. Evaluaci√≥n (`evaluate.py`)

Eval√∫a el modelo guardado. Es clave usar el argumento `-t` para probar la sensibilidad (umbral) de la clasificaci√≥n binaria (por defecto es 0.5).

```bash
# Ejemplo de Evaluaci√≥n Est√°ndar (Umbral 0.5)
python src/cnn/binary_crossentropy/evaluate.py ./data -m src/cnn/binary_crossentropy/best_model.keras -t 0.5 -r report_bce_t050.json

# Ejemplo de Evaluaci√≥n con Umbral Ajustado (0.75)
python src/cnn/binary_crossentropy/evaluate.py ./data -m src/cnn/binary_crossentropy/best_model.keras -t 0.75 -r report_bce_t075.json
```

#### 3. Inferencia (`inference.py`) Prueba

Prueba el modelo en im√°genes de la carpeta `prueba/`.

```bash
python src/cnn/binary_crossentropy/inference.py ./prueba -m src/cnn/binary_crossentropy/best_model.keras -t 0.5
```

### II. Escenario: Deep Learning con Focal Loss (Recomendado para Desbalance)

Este modelo utiliza Focal Loss y un sampling avanzado en el dataloader para mitigar el sesgo por desbalance.

Este modelo es el enfoque principal para mejorar el rendimiento de la clase minoritaria ("Sana") mediante la p√©rdida focal y t√©cnicas de sampling.

#### 1. Entrenamiento (`train.py`)

Utiliza el par√°metro `-a` (`--alpha`) para configurar la p√©rdida focal (`-a 0.15` favorece m√°s el enfoque en la clase Plaga).

```bash
# -e: 25 √©pocas, -a: Alpha de 0.50 para Focal Loss.
python src/cnn/focal_loss/train.py ./data -e 20 -a 0.50
```

#### 2. Evaluaci√≥n (`evaluate.py`)
Eval√∫a el modelo con Focal Loss. Aqu√≠ es donde se recomienda probar diferentes umbrales si el Recall en la clase "Sana" es bajo.

Eval√∫a el modelo guardado (`best_model.keras`).

```bash
python src/cnn/focal_loss/evaluate.py ./data -m src/cnn/focal_loss/best_model.keras -t 0.5
```

#### 3. Inferencia (`inference.py`) Prueba

```bash
python src/cnn/focal_loss/inference.py ./prueba -m src/cnn/focal_loss/best_model.keras -t 0.5
```

### II. Escenario: Machine Learning Cl√°sico (Random Forest)

Este enfoque usa la CNN (MobileNetV2) solo para extraer caracter√≠sticas y clasifica con Random Forest (entrena un clasificador no basado en gradiente (RF)).

#### 1. Extracci√≥n de Caracter√≠sticas y Entrenamiento (`train.py`)

El `train.py` en RF primero extrae caracter√≠sticas de todas las im√°genes (proceso que puede ser lento) y luego entrena el clasificador RF, guard√°ndolo como un archivo `.joblib.`

Este proceso es m√°s lento porque primero extrae caracter√≠sticas de todas las im√°genes. El modelo se guarda como `.joblib`.

```bash
# El modelo RF (.joblib) se guardar√° en src/rf/models/
python src/rf/train.py ./data
```

<b>‚ö†Ô∏èIMPORTANTE:</b> Anota la ruta del archivo `.joblib` generado (ej: `src/rf/models/random_forest_20251103_0038.joblib`).

#### 2. Evaluaci√≥n (`evaluate.py`)
Usa la ruta exacta del modelo `.joblib` para el argumento `-m`.

```bash
# REEMPLAZA <MODELO_RF.joblib> con tu ruta real.
python src/rf/evaluate.py ./data -m src/rf/models/random_forest_GUARDADO.joblib
```

#### 3. Inferencia (`inference.py`) Prueba

```bash
# REEMPLAZA <MODELO_RF.joblib> con tu ruta real.
python src/rf/inference.py ./prueba -m src/rf/models/random_forest_GUARDADO.joblib
```

## üî¨ An√°lisis y Comparativa de Resultados

### Enfoque de M√©tricas

Dada la naturaleza cr√≠tica de la detecci√≥n de plagas y el alto desbalance de clases, la m√©trica m√°s importante es el Recall de la clase "Sana" y el F1-Score. Un Recall bajo en "Sana" significa que el modelo est√° generando muchos Falsos Negativos (etiquetando muestras "Sana" como "Plaga", lo que provoca falsas alarmas), o lo que es peor, Falsos Positivos de Plaga (si se tiene Recall bajo en Plaga).

| M√©trica | Importancia en este Proyecto |
| :--- | :--- |
| Recall (Plaga) | Cr√≠tico: Indica qu√© porcentaje de plagas reales se detectaron. Debe ser lo |m√°s cercano a 1.0 posible. |
| Recall (Sana) | Moderado: Indica qu√© porcentaje de plantas sanas se clasificaron correctamente. |
| F1-Score | General: El mejor indicador para evaluar el rendimiento general, ya que balancea Precision y Recall. |

----

Tras ejecutar las evaluaciones de los tres escenarios, encontrar√°s los reportes de clasificaci√≥n en formato JSON (y las matrices de confusi√≥n ploteadas) dentro de las carpetas de resultados de cada modelo (`src/cnn/.../results/` o `src/rf/results/`).

### M√©tricas Clave

La m√©trica m√°s importante en este contexto, dado el desbalance y el costo de un Falso Negativo (no detectar una plaga), es el Recall de la clase "Sana" y el F1-Score de la clase minoritaria:

| M√©trica | Enfoque | Interpretaci√≥n para "Sana" |
| :--- | :--- | :--- |
|Recall | Deep Learning / RF | ¬øCu√°ntas muestras de "Sana" se detectaron correctamente? |
|Precision | Deep Learning / RF | De todas las muestras predichas como "Sana", ¬øcu√°ntas eran realmente "Sana"? |
|F1-Score | Deep Learning / RF | Promedio arm√≥nico de Precision y Recall. El mejor indicador de rendimiento balanceado. |

<b>Objetivo:</b> El mejor modelo ser√° aquel que logre un alto Recall para la clase Plaga (para no dejar ninguna plaga sin identificar) sin sacrificar demasiado el Recall de la clase Sana (para evitar la mayor√≠a de falsas alarmas).