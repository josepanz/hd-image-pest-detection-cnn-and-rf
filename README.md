# üåø Tesis Plagas con Im√°genes HD: Detecci√≥n en Cultivos de Papa

Este proyecto implementa y compara **tres escenarios** de clasificaci√≥n para la detecci√≥n de plagas/enfermedades en cultivos de papa a partir de im√°genes de alta resoluci√≥n (HD). El objetivo principal es evaluar c√≥mo diferentes funciones de p√©rdida y arquitecturas manejan el alto desbalance de clases del dataset.

## üìÇ Estructura del Proyecto

El c√≥digo est√° organizado por el tipo de clasificador (CNN o RF) y la funci√≥n de p√©rdida utilizada.

| Carpeta | Contenido | Descripci√≥n |
| :--- | :--- | :--- |
| `data/` | `Plaga/`, `Sana/` | Directorio principal de los datos de entrenamiento y validaci√≥n. **Debe contener las im√°genes.** |
| `data/Plaga` | Im√°genes HD | Muestras de plantaciones de papas con plagas/enfermedades. |
| `data/Sana` | Im√°genes HD | Muestras de plantaciones de papas sanas. |
| `data/shapefiles` | Archivos multiespectrales | Archivos utilizados para analizar los algoritmos a imagenes multiespectrales. |
| `data/measurements` | Archivos xls del modelo multiespectral | Archivos de mediciones. |
| `data/multispectral_images` | Carpeta que contiene carpetas con imagenes TIF | Utilizadas para el modelo multiespectral. |
| `data/multispectral_images/2022_06_15__eko_ecobreed` | Carpeta que contiene imagenes TIF | Utilizadas para el modelo multiespectral. |
| `data/multispectral_images/2022_06_15__konv_ecobreed` | Carpeta que contiene imagenes TIF | Utilizadas para el modelo multiespectral. |
| `data/multispectral_images/2022_07_11__eko_ecobreed` | Carpeta que contiene imagenes TIF | Utilizadas para el modelo multiespectral. |
| `data/multispectral_images/2022_07_11__konv_ecobreed` | Carpeta que contiene imagenes TIF | Utilizadas para el modelo multiespectral. |
| `data/multispectral_images/2022_07_20__eko_ecobreed` | Carpeta que contiene imagenes TIF | Utilizadas para el modelo multiespectral. |
| `data/multispectral_images/2022_07_20__konv_ecobreed` | Carpeta que contiene imagenes TIF | Utilizadas para el modelo multiespectral. |
| `src/` | | C√≥digo fuente principal. |
| `src/cnn/binary_crossentropy/` | | Modelo **Deep Learning (MobileNetV2)** con p√©rdida est√°ndar. |
| `src/cnn/focal_loss/` | | Modelo **Deep Learning (MobileNetV2)** con p√©rdida **Focal Loss** (para desbalance). |
| `src/rf/` | | Modelo **Machine Learning Cl√°sico (Random Forest)** usando CNN para extracci√≥n de *features*. |
| `prueba/` | Im√°genes nuevas | Im√°genes de prueba para los scripts de inferencia (`inference.py`). |
| `requirements.txt`| Dependencias | Lista de librer√≠as necesarias. |

---

## ‚öôÔ∏è Configuraci√≥n y Requisitos

### 1. Crear y Activar el Entorno Virtual

Es fundamental usar un entorno virtual (`venv`) para evitar conflictos de librer√≠as. Ejecuta estos comandos en la carpeta ra√≠z del proyecto.

```bash
# Crear el entorno virtual
python -m venv venv

# Activar en Windows
.\venv\Scripts\activate

# Activar en Linux/macOS
source venv/bin/activate
```

### 2. Instalar Dependencias

Aseg√∫rate de tener un archivo `requirements.txt` que liste todas las librer√≠as necesarias (TensorFlow, etc.).

```bash
pip install -r requirements.txt
```

### 3. Descargar archivos para pruebas 
**<u>Articulo en linea:</u>** <span><a href="https://data.4tu.nl/datasets/c5f013d0-85e0-4feb-b653-a3c59683a2bc">TTADDA_NARO_2023: A subset of the multi-season RGB and multispectral TTADDA-UAV potato dataset</a> (TTADDA_NARO_2023: Un subconjunto del conjunto de datos de patatas TTADDA-UAV RGB y multiespectral de varias temporadas)</span>

**Descarga Directa:** <a href="https://data.4tu.nl/file/c5f013d0-85e0-4feb-b653-a3c59683a2bc/1baf67c0-9522-4099-b058-72ed0084c1a4">TTADDA_NARO_2023.zip</a>

**Otros archivos:** 
- <a href="https://data.4tu.nl/file/c5f013d0-85e0-4feb-b653-a3c59683a2bc/51b2b3c1-4f4c-4223-8697-aed0d93f5d4d">MIAPPE_Minimal_Spreadsheet_Template_TTADDAv4.xlsx</a>
- <a href="https://data.4tu.nl/file/c5f013d0-85e0-4feb-b653-a3c59683a2bc/24478a60-1479-43af-80d3-5cd017fdc6bc">README_TTADDA_NARO_2023.txt</a>

#### Base del estudio y datos adicionales.
- <span>**Estudio:** <a href="https://www.sciencedirect.com/science/article/pii/S2352340925007280">TTADDA-UAV: A Multi-Season RGB and Multispectral UAV Dataset of Potato Fields Collected in Japan and the Netherlands</a>. (TTADDA-UAV: Un conjunto de datos UAV RGB y multiespectrales multitemporales de campos de patatas recopilados en Jap√≥n y los Pa√≠ses Bajos.) <a href="https://data.4tu.nl/collections/936b5772-09fc-4856-983d-1f9cc2f38d15">DATOS</a>
</span>

  - **TTADDA_NARO_2022:** <a href="https://data.4tu.nl/datasets/ed9b9cd6-8d69-411b-9054-1ecce543ac1b">TTADDA_NARO_2022: A subset of the multi-season RGB and multispectral TTADDA-UAV potato dataset</a> (TTADDA_NARO_2022: Un subconjunto del conjunto de datos de patatas TTADDA-UAV RGB y multiespectral de varias temporadas)

  - **TTADDA_NARO_2021:** <a href="https://data.4tu.nl/datasets/f2307c47-9a1a-474a-a0d9-e09ee1b7512c">TTADDA_NARO_2021: A subset of the multi-season RGB and multispectral TTADDA-UAV potato dataset</a> (TTADDA_NARO_2021: Un subconjunto del conjunto de datos de patatas TTADDA-UAV RGB y multiespectral de varias temporadas)
  
  - **TTADDA_WUR_2022:** <a href="https://data.4tu.nl/datasets/1f628b56-3246-4aab-accd-1193b1566763">TTADDA_WUR_2022: A subset of the multi-season RGB and multispectral TTADDA-UAV potato dataset</a> (TTADDA_WUR_2022: Un subconjunto del conjunto de datos de patatas TTADDA-UAV RGB y multiespectral de varias temporadas)

  - **TTADDA_WUR_2023:** <a href="https://data.4tu.nl/datasets/75c01fac-f00a-4980-8cd8-cd4499f1aa98">TTADDA_WUR_2023: A subset of the multi-season RGB and multispectral TTADDA-UAV potato dataset
</a> (TTADDA_WUR_2023: Un subconjunto del conjunto de datos de patatas TTADDA-UAV RGB y multiespectral de varias temporadas)


## üöÄ Gu√≠a de Ejecuci√≥n Paso a Paso
### I. Escenario: Deep Learning con Binary Cross-Entropy (L√≠nea Base)

Este modelo establece la referencia utilizando la funci√≥n de p√©rdida est√°ndar.

#### 1. Entrenamiento (`train.py`)

El script entrena el modelo CNN y guarda el mejor peso monitoreando el Recall o la Loss de validaci√≥n (dependiendo de la configuraci√≥n del callback).

```bash
python src/cnn/binary_crossentropy/train.py ./data
```

#### 2. Evaluaci√≥n (`evaluate.py`)

Eval√∫a el modelo guardado. Es clave usar el argumento `-t` para probar la sensibilidad (umbral) de la clasificaci√≥n binaria (por defecto es 0.5).

```bash
# Ejemplo de Evaluaci√≥n Est√°ndar (Umbral 0.5)
python src/cnn/binary_crossentropy/evaluate.py ./data -m src/cnn/binary_crossentropy/best_model.keras -t 0.5 -r report_bce_t050.json

# Ejemplo de Evaluaci√≥n con Umbral Ajustado (0.75)
python src/cnn/binary_crossentropy/evaluate.py ./data -m src/cnn/binary_crossentropy/best_model.keras -t 0.75 -r report_bce_t075.json
```

#### 3. Inferencia (`inference.py`) Prueba

Prueba el modelo en im√°genes de la carpeta `prueba/`.

```bash
python src/cnn/binary_crossentropy/inference.py ./prueba -m src/cnn/binary_crossentropy/best_model.keras -t 0.5
```

### II. Escenario: Deep Learning con Focal Loss (Recomendado para Desbalance)

Este modelo utiliza Focal Loss y un sampling avanzado en el dataloader para mitigar el sesgo por desbalance.

Este modelo es el enfoque principal para mejorar el rendimiento de la clase minoritaria ("Sana") mediante la p√©rdida focal y t√©cnicas de sampling.

#### 1. Entrenamiento (`train.py`)

Utiliza el par√°metro `-a` (`--alpha`) para configurar la p√©rdida focal (`-a 0.15` favorece m√°s el enfoque en la clase Plaga).

```bash
# -e: 25 √©pocas, -a: Alpha de 0.50 para Focal Loss.
python src/cnn/focal_loss/train.py ./data -e 20 -a 0.50
```

#### 2. Evaluaci√≥n (`evaluate.py`)
Eval√∫a el modelo con Focal Loss. Aqu√≠ es donde se recomienda probar diferentes umbrales si el Recall en la clase "Sana" es bajo.

Eval√∫a el modelo guardado (`best_model.keras`).

```bash
python src/cnn/focal_loss/evaluate.py ./data -m src/cnn/focal_loss/best_model.keras -t 0.5
```

#### 3. Inferencia (`inference.py`) Prueba

```bash
python src/cnn/focal_loss/inference.py ./prueba -m src/cnn/focal_loss/best_model.keras -t 0.5
```

### II. Escenario: Machine Learning Cl√°sico (Random Forest)

Este enfoque usa la CNN (MobileNetV2) solo para extraer caracter√≠sticas y clasifica con Random Forest (entrena un clasificador no basado en gradiente (RF)).

#### 1. Extracci√≥n de Caracter√≠sticas y Entrenamiento (`train.py`)

El `train.py` en RF primero extrae caracter√≠sticas de todas las im√°genes (proceso que puede ser lento) y luego entrena el clasificador RF, guard√°ndolo como un archivo `.joblib.`

Este proceso es m√°s lento porque primero extrae caracter√≠sticas de todas las im√°genes. El modelo se guarda como `.joblib`.

```bash
# El modelo RF (.joblib) se guardar√° en src/rf/models/
python src/rf/train.py ./data
```

<b>‚ö†Ô∏èIMPORTANTE:</b> Anota la ruta del archivo `.joblib` generado (ej: `src/rf/models/random_forest_20251103_0038.joblib`).

#### 2. Evaluaci√≥n (`evaluate.py`)
Usa la ruta exacta del modelo `.joblib` para el argumento `-m`.

```bash
# REEMPLAZA <MODELO_RF.joblib> con tu ruta real.
python src/rf/evaluate.py ./data -m src/rf/models/random_forest_GUARDADO.joblib
```

#### 3. Inferencia (`inference.py`) Prueba

```bash
# REEMPLAZA <MODELO_RF.joblib> con tu ruta real.
python src/rf/inference.py ./prueba -m src/rf/models/random_forest_GUARDADO.joblib
```

### IV. Escenario multiespectral con cnn focal loss o binary crossentropy

#### 0. Verificar la descarga y descomprimir los archivos en una carpeta con nombre `multispectral_images` en el directorio -> `data/` con el respectivo nombre del archivo, ej: `2022_07_20__konv_ecobreed/Ecobreed_krompir_EKO_15_06_2022_transparent_reflectance_blue_modified.tif`
- data/2022_06_15__eko_ecobreed.zip
- data/2022_06_15__konv_ecobreed.zip
- data/2022_07_11__eko_ecobreed.zip
- data/2022_07_11__konv_ecobreed.zip
- data/2022_07_20__eko_ecobreed.zip
- data/2022_07_20__konv_ecobreed.zip

#### 1. Entrenamiento (`train_multiespectral.py`)

```bash
# para funcion de perdida binary crossentropy por defecto
python src/multiespectral/train_multiespectral.py --epochs 70 --batch_size 32
```

```bash
# para funcion de perdida focal loss
python src/multiespectral/train_multiespectral.py --epochs 70 --batch_size 32 -f focal_loss 
```

```bash
# Si deseas permitir el fine-tuning (entrenamiento de las capas base de MobileNetV2, lo cual requiere m√°s recursos y tiempo):
python src/multiespectral/train_multiespectral.py --epochs 70 --batch_size 32 --fine_tune
```

#### 2. Evaluaci√≥n (`evaluate_multiespectral.py`)

```bash
# Evaluar modelo Multiespectral (5 canales)
python src/multiespectral/evaluate_multiespectral.py -m src\multiespectral\results_multispectral\best_models_ms\best_model_ms_base.keras -t 0.5
```

#### 3. Inferencia (`inference_multiespectral.py`) Prueba

```bash
# probar sobre una imagen
python src/multiespectral/inference_multiespectral.py -p data/multispectral_images/2022_06_15__eko_ecobreed -m src/multiespectral/results_multispectral/best_models_ms/best_model_ms_base.keras -t 0.60
```

```bash
# probar toda la carpeta de prueba
python src/multiespectral/inference_multiespectral.py -m src/multiespectral/results_multispectral/best_models_ms/best_model_ms_base.keras -t 0.60 -all True
```

## üî¨ An√°lisis y Comparativa de Resultados

### Enfoque de M√©tricas

Dada la naturaleza cr√≠tica de la detecci√≥n de plagas y el alto desbalance de clases, la m√©trica m√°s importante es el Recall de la clase "Sana" y el F1-Score. Un Recall bajo en "Sana" significa que el modelo est√° generando muchos Falsos Negativos (etiquetando muestras "Sana" como "Plaga", lo que provoca falsas alarmas), o lo que es peor, Falsos Positivos de Plaga (si se tiene Recall bajo en Plaga).

| M√©trica | Importancia en este Proyecto |
| :--- | :--- |
| Recall (Plaga) | Cr√≠tico: Indica qu√© porcentaje de plagas reales se detectaron. Debe ser lo |m√°s cercano a 1.0 posible. |
| Recall (Sana) | Moderado: Indica qu√© porcentaje de plantas sanas se clasificaron correctamente. |
| F1-Score | General: El mejor indicador para evaluar el rendimiento general, ya que balancea Precision y Recall. |

----

Tras ejecutar las evaluaciones de los tres escenarios, encontrar√°s los reportes de clasificaci√≥n en formato JSON (y las matrices de confusi√≥n ploteadas) dentro de las carpetas de resultados de cada modelo (`src/cnn/.../results/` o `src/rf/results/`).

### M√©tricas Clave

La m√©trica m√°s importante en este contexto, dado el desbalance y el costo de un Falso Negativo (no detectar una plaga), es el Recall de la clase "Sana" y el F1-Score de la clase minoritaria:

| M√©trica | Enfoque | Interpretaci√≥n para "Sana" |
| :--- | :--- | :--- |
|Recall | Deep Learning / RF | ¬øCu√°ntas muestras de "Sana" se detectaron correctamente? |
|Precision | Deep Learning / RF | De todas las muestras predichas como "Sana", ¬øcu√°ntas eran realmente "Sana"? |
|F1-Score | Deep Learning / RF | Promedio arm√≥nico de Precision y Recall. El mejor indicador de rendimiento balanceado. |

## Definiciones: ¬øCu√°les son los positivos y negativos? `Positivos = Sanos`, `Negativos = Plagas`
<a href= "https://www.youtube.com/watch?v=H8FSfqxRWmA">YouTube</a> | <a href="https://codificandobits.com/blog/precision-recall-f-score/">Blog</a> | <a href="https://colab.research.google.com/drive/10xngRuU0kyxGildcx7YfxQzjrk_nXXU-?usp=sharing">Colab</a>
- **Verdaderos Positivos / True Positive (VP o TP):** `"sanos"` clasificados **_realmente_** como `"sanos"`.
- **Falsos Positivos / False Positive (FP o FP):** `"plagas"` clasificados **_equivocadamente_** como `"sanos"`.
- **Verdaderos Negativos / True Negative (VN o TN):** `"plagas"` clasificados **_realmente_** como `"plagas"`.
- **Falsos Negativos / False Negative (FN o FN):** `"sanos"` clasificados **_equivocadamente_** como `"plagas"`.


<b>Objetivo:</b> El mejor modelo ser√° aquel que logre un alto Recall para la clase Plaga (para no dejar ninguna plaga sin identificar) sin sacrificar demasiado el Recall de la clase Sana (para evitar la mayor√≠a de falsas alarmas).